{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:09:10.999462Z",
     "start_time": "2024-09-08T17:09:10.995111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from arch import arch_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n"
   ],
   "id": "532adc2f53d9d631",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:09:11.022225Z",
     "start_time": "2024-09-08T17:09:11.008470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def find_best_arima_order(time_series, p_range=(0, 3), d_range=(0, 1), q_range=(0, 3)):\n",
    "    \"\"\"\n",
    "    Find the best ARIMA (p, d, q) order based on the lowest AIC score.\n",
    "    \n",
    "    Parameters:\n",
    "    time_series (pd.Series): The time series data (stock prices or log returns).\n",
    "    p_range (tuple): Range of p values to try.\n",
    "    d_range (tuple): Range of d values to try.\n",
    "    q_range (tuple): Range of q values to try.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Best (p, d, q) values based on AIC.\n",
    "    \"\"\"\n",
    "    best_aic = float('inf')\n",
    "    best_order = None\n",
    "\n",
    "    for p in range(p_range[0], p_range[1] + 1):\n",
    "        for d in range(d_range[0], d_range[1] + 1):\n",
    "            for q in range(q_range[0], q_range[1] + 1):\n",
    "                try:\n",
    "                    # Fit ARIMA model\n",
    "                    model = ARIMA(time_series, order=(p, d, q))\n",
    "                    fitted_model = model.fit()\n",
    "\n",
    "                    # Check AIC and store the best order\n",
    "                    if fitted_model.aic < best_aic:\n",
    "                        best_aic = fitted_model.aic\n",
    "                        best_order = (p, d, q)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    return best_order\n"
   ],
   "id": "56473e41f7a94f98",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:09:11.033210Z",
     "start_time": "2024-09-08T17:09:11.024236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decompose_data(data):\n",
    "    \"\"\"\n",
    "    Decompose time series data into linear, seasonal (stable) parts and residual (unstable) parts.\n",
    "    Uses ARIMA for long-term trends and GARCH for modeling volatility clusters.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.Series): Stock price time series.\n",
    "    \n",
    "    Returns:\n",
    "    - long_term: ARIMA modeled long-term trend data.\n",
    "    - seasonal: GARCH modeled volatility seasonal data.\n",
    "    - residual: Unstable (residual) part of the time series.\n",
    "    \"\"\"\n",
    "    # Find the best ARIMA order dynamically\n",
    "    best_arima_order = find_best_arima_order(data, p_range=(0, 3), d_range=(0, 1), q_range=(0, 3))\n",
    "    print(f\"Best ARIMA order found: {best_arima_order}\")\n",
    "\n",
    "    # Fit ARIMA model (long-term trend) using the best ARIMA order\n",
    "    arima_model = ARIMA(data, order=best_arima_order)\n",
    "    arima_fitted = arima_model.fit()\n",
    "    long_term = arima_fitted.fittedvalues\n",
    "\n",
    "    print(arima_fitted.summary())\n",
    "\n",
    "    # Fit GARCH model (seasonal effects)\n",
    "    garch_model = arch_model(data - long_term, vol='Garch', p=1, q=1)\n",
    "    # Fit the model with optimization options\n",
    "    options = {'maxiter': 1000, 'disp': False}  # Control the optimization process\n",
    "    garch_fitted = garch_model.fit(update_freq=5, disp='off', options=options)\n",
    "    seasonal = garch_fitted.conditional_volatility\n",
    "\n",
    "    if garch_fitted.convergence_flag == 0:\n",
    "        print(\"GARCH Model converged successfully\")\n",
    "    else:\n",
    "        print(\"Warning: GARCH Model did not converge\")\n",
    "\n",
    "    print(garch_fitted.summary())\n",
    "\n",
    "    # Calculate residual\n",
    "    residual = data - long_term - seasonal\n",
    "\n",
    "    return long_term, seasonal, residual\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:09:11.043326Z",
     "start_time": "2024-09-08T17:09:11.034217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_data(long_term, seasonal, residual, train_size=0.75):\n",
    "    \"\"\"\n",
    "    Split data into train and test sets for each part of the time series.\n",
    "    \n",
    "    Parameters:\n",
    "    - long_term, seasonal, residual: Components of the decomposed time series.\n",
    "    - train_size (float): Proportion of data to use for training.\n",
    "    \n",
    "    Returns:\n",
    "    - Train and test sets for each part.\n",
    "    \"\"\"\n",
    "    split_index = int(len(long_term) * train_size)\n",
    "\n",
    "    train_lt, test_lt = long_term[:split_index], long_term[split_index:]\n",
    "    train_st, test_st = seasonal[:split_index], seasonal[split_index:]\n",
    "    train_res, test_res = residual[:split_index], residual[split_index:]\n",
    "\n",
    "    return (train_lt, test_lt), (train_st, test_st), (train_res, test_res)\n"
   ],
   "id": "1e13ce2565aebff6",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:09:11.064701Z",
     "start_time": "2024-09-08T17:09:11.058812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_lstm_data(data, look_back=5):\n",
    "    \"\"\"\n",
    "    Prepare data for LSTM training.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): Input data for LSTM.\n",
    "    - look_back (int): Number of time steps to consider for the LSTM input.\n",
    "    \n",
    "    Returns:\n",
    "    - X, y: Input and output sequences for LSTM.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaled_data = scaler.fit_transform(data.values.reshape(-1, 1))\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_data) - look_back):\n",
    "        X.append(scaled_data[i:i + look_back])\n",
    "        y.append(scaled_data[i + look_back])\n",
    "\n",
    "    return np.array(X), np.array(y), scaler\n"
   ],
   "id": "e70771e5fcabed78",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:09:11.084284Z",
     "start_time": "2024-09-08T17:09:11.077959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Define the LSTM model for forecasting the residual data.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_shape (tuple): Shape of the input data (timesteps, features).\n",
    "    \n",
    "    Returns:\n",
    "    - LSTM model.\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(units=50, input_shape=input_shape))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n"
   ],
   "id": "2cf5f643b098b5bc",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:09:11.093893Z",
     "start_time": "2024-09-08T17:09:11.086291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sine_cosine_algorithm(pop_size, dimensions, lb, ub, max_iters, fitness_func):\n",
    "    \"\"\"\n",
    "    Sine-Cosine Algorithm to optimize the hyperparameters of LSTM and ARIMA.\n",
    "    \n",
    "    Parameters:\n",
    "    - pop_size: Population size.\n",
    "    - dimensions: Number of hyperparameters to optimize.\n",
    "    - lb: Lower bound for each dimension.\n",
    "    - ub: Upper bound for each dimension.\n",
    "    - max_iters: Maximum iterations.\n",
    "    - fitness_func: Fitness function to evaluate each solution.\n",
    "    \n",
    "    Returns:\n",
    "    - Best solution (optimized hyperparameters).\n",
    "    \"\"\"\n",
    "    # Initialize population\n",
    "    pop = np.random.uniform(lb, ub, (pop_size, dimensions))\n",
    "    best_solution = None\n",
    "    best_fitness = float('inf')\n",
    "\n",
    "    for iteration in range(max_iters):\n",
    "        for i in range(pop_size):\n",
    "            # Evaluate fitness of each candidate solution\n",
    "            fitness = fitness_func(pop[i])\n",
    "\n",
    "            if fitness < best_fitness:\n",
    "                best_fitness = fitness\n",
    "                best_solution = pop[i]\n",
    "\n",
    "            # Update position based on Sine-Cosine update rule\n",
    "            r1, r2, r3, r4 = random.random(), random.random(), random.random(), random.random()\n",
    "            if r4 < 0.5:\n",
    "                pop[i] += r1 * np.sin(r2) * abs(r3 * best_solution - pop[i])\n",
    "            else:\n",
    "                pop[i] += r1 * np.cos(r2) * abs(r3 * best_solution - pop[i])\n",
    "\n",
    "        print(f\"Iteration {iteration}: Best Fitness = {best_fitness}\")\n",
    "\n",
    "    return best_solution\n"
   ],
   "id": "b0a7526d7480b759",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:09:11.118125Z",
     "start_time": "2024-09-08T17:09:11.112474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forecast_arima_garch_lstm_sca(data, best_params, train_data, test_data):\n",
    "    \"\"\"\n",
    "    Forecast stock prices using ARIMA-GARCH-LSTM-SCA model.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: Original stock price data.\n",
    "    - best_params: Optimized parameters from SCA.\n",
    "    - train_data: Training data.\n",
    "    - test_data: Testing data.\n",
    "    \n",
    "    Returns:\n",
    "    - Predictions.\n",
    "    \"\"\"\n",
    "    # Fit ARIMA-GARCH\n",
    "    p, q = int(best_params[0]), int(best_params[1])\n",
    "    arima_garch_model = arch_model(train_data, vol='Garch', p=p, q=q)\n",
    "    fitted_model = arima_garch_model.fit(disp='off')\n",
    "\n",
    "    # Forecast test data\n",
    "    forecast_vol = fitted_model.forecast(horizon=len(test_data))\n",
    "\n",
    "    # Combine results and return\n",
    "    predictions = test_data + forecast_vol.variance\n",
    "    return predictions\n"
   ],
   "id": "c8a645bcdcc6bfcd",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:09:11.132678Z",
     "start_time": "2024-09-08T17:09:11.127747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the fitness function for SCA (minimizing RMSE between actual and predicted values)\n",
    "def fitness_function(params):\n",
    "    p, q = int(params[0]), int(params[1])\n",
    "    arima_garch_model = arch_model(train_lt, vol='Garch', p=p, q=q)\n",
    "    fitted_model = arima_garch_model.fit(disp='off')\n",
    "\n",
    "    # Forecast and calculate RMSE\n",
    "    forecast_vol = fitted_model.forecast(horizon=len(test_lt))\n",
    "    predictions = test_lt + forecast_vol.variance\n",
    "\n",
    "    return mean_squared_error(test_lt, predictions)"
   ],
   "id": "f92f1b775db0995e",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:09:11.141619Z",
     "start_time": "2024-09-08T17:09:11.133687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert log returns back to prices\n",
    "def log_returns_to_prices(log_returns, initial_price):\n",
    "    \"\"\"\n",
    "    Convert log returns to prices.\n",
    "    \n",
    "    Parameters:\n",
    "    log_returns (np.array): Array of log returns.\n",
    "    initial_price (float): The initial price from which to start the conversion.\n",
    "    \n",
    "    Returns:\n",
    "    np.array: Array of predicted prices.\n",
    "    \"\"\"\n",
    "    predicted_prices = np.zeros_like(log_returns)\n",
    "    predicted_prices[0] = initial_price\n",
    "    for t in range(1, len(log_returns)):\n",
    "        predicted_prices[t] = predicted_prices[t-1] * np.exp(log_returns[t])\n",
    "    return predicted_prices"
   ],
   "id": "e1ea0871fcd528c4",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:09:11.158749Z",
     "start_time": "2024-09-08T17:09:11.154494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combine_predictions(arima_garch_predictions, lstm_predictions):\n",
    "    \"\"\"\n",
    "    Combine ARIMA-GARCH and LSTM predictions using a direct summation method.\n",
    "    \n",
    "    Parameters:\n",
    "    - arima_garch_predictions (np.array or pd.Series): Predictions from the ARIMA-GARCH model.\n",
    "    - lstm_predictions (np.array or pd.Series): Predictions from the LSTM model.\n",
    "    \n",
    "    Returns:\n",
    "    - combined_predictions (np.array): Summation of both predictions.\n",
    "    \"\"\"\n",
    "    # Ensure both prediction arrays are the same shape\n",
    "    if len(arima_garch_predictions) != len(lstm_predictions):\n",
    "        raise ValueError(\"The predictions from ARIMA-GARCH and LSTM models must have the same length.\")\n",
    "\n",
    "    # Combine the predictions by adding them together\n",
    "    combined_predictions = arima_garch_predictions + lstm_predictions\n",
    "\n",
    "    return combined_predictions\n"
   ],
   "id": "2355ba23ad30f9f5",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T17:19:14.232612Z",
     "start_time": "2024-09-08T17:18:35.585201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "from arch.utility.exceptions import DataScaleWarning\n",
    "\n",
    "# Suppress the DataScaleWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DataScaleWarning)\n",
    "\n",
    "# Load preprocessed stock data with raw prices (not log returns)\n",
    "data = pd.read_csv('../data/processed/AAPL_processed.csv')\n",
    "prices = data['Adj Close']\n",
    "\n",
    "# Decompose the price series to extract long-term, seasonal, and residual components\n",
    "long_term, seasonal, residual = decompose_data(prices)\n",
    "(train_lt, test_lt), (train_st, test_st), (train_res, test_res) = split_data(long_term, seasonal, residual)\n",
    "\n",
    "# Define bounds for p and q in ARIMA-GARCH model optimization\n",
    "lb = [1, 1]  # Lower bounds for ARIMA-GARCH p, q parameters\n",
    "ub = [5, 5]  # Upper bounds for ARIMA-GARCH p, q parameters\n",
    "\n",
    "# Optimize ARIMA-GARCH parameters using SCA (Sine Cosine Algorithm)\n",
    "best_params = sine_cosine_algorithm(pop_size=30, dimensions=2, lb=lb, ub=ub, max_iters=50, fitness_func=fitness_function)\n",
    "\n",
    "print(f\"Best parameters found by SCA: {best_params}\")\n",
    "\n",
    "# Fit ARIMA-GARCH Model using the optimized parameters\n",
    "# Use the long-term component of the price data (train_lt) in this case\n",
    "arima_garch_predictions = forecast_arima_garch_lstm_sca(prices, best_params, train_lt, test_lt)\n",
    "\n",
    "# Prepare LSTM training data (using the residual part from decomposition)\n",
    "X_train, y_train, scaler = prepare_lstm_data(pd.DataFrame(train_res))\n",
    "\n",
    "# Create LSTM model based on the input shape of the training data\n",
    "lstm_model = create_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "# Train the LSTM model on residuals\n",
    "lstm_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=2)\n",
    "\n",
    "# Make LSTM predictions\n",
    "lstm_predictions = lstm_model.predict(X_train)\n",
    "\n",
    "# Combine ARIMA-GARCH predictions and LSTM residual predictions\n",
    "# Depending on your strategy (e.g., weighted combination), combine the forecasts\n",
    "combined_forecast = combine_predictions(arima_garch_predictions, lstm_predictions)\n",
    "# Ensure that predictions and actual prices have consistent lengths\n",
    "\n"
   ],
   "id": "bd7a0d98368d82c6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA order found: (3, 0, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:              Adj Close   No. Observations:                 3521\n",
      "Model:                 ARIMA(3, 0, 2)   Log Likelihood               -6264.802\n",
      "Date:                Sun, 08 Sep 2024   AIC                          12543.605\n",
      "Time:                        12:19:14   BIC                          12586.770\n",
      "Sample:                             0   HQIC                         12559.005\n",
      "                               - 3521                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         57.7277   1381.103      0.042      0.967   -2649.184    2764.640\n",
      "ar.L1         -0.8595      0.005   -172.215      0.000      -0.869      -0.850\n",
      "ar.L2          0.8842      0.002    522.320      0.000       0.881       0.888\n",
      "ar.L3          0.9753      0.005    199.113      0.000       0.966       0.985\n",
      "ma.L1          1.8509      0.007    279.035      0.000       1.838       1.864\n",
      "ma.L2          0.9586      0.007    146.394      0.000       0.946       0.971\n",
      "sigma2         2.0548      0.020    104.468      0.000       2.016       2.093\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.54   Jarque-Bera (JB):             17513.49\n",
      "Prob(Q):                              0.46   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):             101.70   Skew:                            -0.01\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        13.93\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "GARCH Model converged successfully\n",
      "                     Constant Mean - GARCH Model Results                      \n",
      "==============================================================================\n",
      "Dep. Variable:                   None   R-squared:                       0.000\n",
      "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                      GARCH   Log-Likelihood:               -3423.23\n",
      "Distribution:                  Normal   AIC:                           6854.46\n",
      "Method:            Maximum Likelihood   BIC:                           6879.13\n",
      "                                        No. Observations:                 3521\n",
      "Date:                Sun, Sep 08 2024   Df Residuals:                     3520\n",
      "Time:                        12:19:14   Df Model:                            1\n",
      "                                 Mean Model                                 \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "mu             0.0306  6.686e-03      4.573  4.801e-06 [1.747e-02,4.368e-02]\n",
      "                              Volatility Model                              \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "omega      3.2480e-03  1.057e-03      3.073  2.117e-03 [1.177e-03,5.319e-03]\n",
      "alpha[1]       0.1778  1.621e-02     10.970  5.318e-28     [  0.146,  0.210]\n",
      "beta[1]        0.8222  1.614e-02     50.958      0.000     [  0.791,  0.854]\n",
      "============================================================================\n",
      "\n",
      "Covariance estimator: robust\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [881, 1]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[53], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m ub \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m5\u001B[39m]  \u001B[38;5;66;03m# Upper bounds for ARIMA-GARCH p, q parameters\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# Optimize ARIMA-GARCH parameters using SCA (Sine Cosine Algorithm)\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m best_params \u001B[38;5;241m=\u001B[39m \u001B[43msine_cosine_algorithm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpop_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdimensions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlb\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mub\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mub\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfitness_func\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfitness_function\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest parameters found by SCA: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_params\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# Fit ARIMA-GARCH Model using the optimized parameters\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# Use the long-term component of the price data (train_lt) in this case\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[47], line 24\u001B[0m, in \u001B[0;36msine_cosine_algorithm\u001B[1;34m(pop_size, dimensions, lb, ub, max_iters, fitness_func)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m iteration \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(max_iters):\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(pop_size):\n\u001B[0;32m     23\u001B[0m         \u001B[38;5;66;03m# Evaluate fitness of each candidate solution\u001B[39;00m\n\u001B[1;32m---> 24\u001B[0m         fitness \u001B[38;5;241m=\u001B[39m \u001B[43mfitness_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m fitness \u001B[38;5;241m<\u001B[39m best_fitness:\n\u001B[0;32m     27\u001B[0m             best_fitness \u001B[38;5;241m=\u001B[39m fitness\n",
      "Cell \u001B[1;32mIn[49], line 11\u001B[0m, in \u001B[0;36mfitness_function\u001B[1;34m(params)\u001B[0m\n\u001B[0;32m      8\u001B[0m forecast_vol \u001B[38;5;241m=\u001B[39m fitted_model\u001B[38;5;241m.\u001B[39mforecast(horizon\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(test_lt))\n\u001B[0;32m      9\u001B[0m predictions \u001B[38;5;241m=\u001B[39m test_lt \u001B[38;5;241m+\u001B[39m forecast_vol\u001B[38;5;241m.\u001B[39mvariance\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmean_squared_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_lt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32mC:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:506\u001B[0m, in \u001B[0;36mmean_squared_error\u001B[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001B[0m\n\u001B[0;32m    501\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m squared:\n\u001B[0;32m    502\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m root_mean_squared_error(\n\u001B[0;32m    503\u001B[0m             y_true, y_pred, sample_weight\u001B[38;5;241m=\u001B[39msample_weight, multioutput\u001B[38;5;241m=\u001B[39mmultioutput\n\u001B[0;32m    504\u001B[0m         )\n\u001B[1;32m--> 506\u001B[0m y_type, y_true, y_pred, multioutput \u001B[38;5;241m=\u001B[39m \u001B[43m_check_reg_targets\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    507\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmultioutput\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    509\u001B[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[0;32m    510\u001B[0m output_errors \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39maverage((y_true \u001B[38;5;241m-\u001B[39m y_pred) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, weights\u001B[38;5;241m=\u001B[39msample_weight)\n",
      "File \u001B[1;32mC:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:111\u001B[0m, in \u001B[0;36m_check_reg_targets\u001B[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001B[39;00m\n\u001B[0;32m     77\u001B[0m \n\u001B[0;32m     78\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    107\u001B[0m \u001B[38;5;124;03m    correct keyword.\u001B[39;00m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    109\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(y_true, y_pred, multioutput, xp\u001B[38;5;241m=\u001B[39mxp)\n\u001B[1;32m--> 111\u001B[0m \u001B[43mcheck_consistent_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    112\u001B[0m y_true \u001B[38;5;241m=\u001B[39m check_array(y_true, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    113\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m check_array(y_pred, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "File \u001B[1;32mC:\\CoDE\\workspace-idea\\everything\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:460\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    458\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[0;32m    459\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 460\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    461\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    462\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[0;32m    463\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [881, 1]"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "eb31f8c18c41a3b3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
