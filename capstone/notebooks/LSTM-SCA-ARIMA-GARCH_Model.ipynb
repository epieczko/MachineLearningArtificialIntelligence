{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T21:08:49.773137Z",
     "start_time": "2024-09-11T21:08:49.769492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from arch import arch_model\n",
    "from keras import models\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.tsa.seasonal as smt\n",
    "from tqdm import tqdm\n"
   ],
   "id": "1e8f91df38a1cf0f",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T21:08:49.777720Z",
     "start_time": "2024-09-11T21:08:49.773137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataPreprocessing:\n",
    "    def __init__(self, data, decomposition_model=\"additive\", rolling_window=12):\n",
    "        self.data = data\n",
    "        self.decomposition_model = decomposition_model\n",
    "        self.rolling_window = rolling_window\n",
    "\n",
    "    def decompose_data(self):\n",
    "        decomposition = smt.seasonal_decompose(self.data, model=self.decomposition_model, period=self.rolling_window)\n",
    "        trend = decomposition.trend.dropna()\n",
    "        seasonal = decomposition.seasonal.dropna()\n",
    "        residual = decomposition.resid.dropna()\n",
    "        return trend, seasonal, residual\n",
    "\n",
    "    def deseasonalize(self):\n",
    "        trend, seasonal, residual = self.decompose_data()\n",
    "        if self.decomposition_model == \"additive\":\n",
    "            deseasonalized_data = self.data - seasonal\n",
    "        elif self.decomposition_model == \"multiplicative\":\n",
    "            deseasonalized_data = self.data / seasonal\n",
    "        return deseasonalized_data.dropna()\n"
   ],
   "id": "2c0c23f9454be86c",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T18:37:24.248753Z",
     "start_time": "2024-09-12T18:37:24.245438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def arima_forecast(train_data, test_data, order):\n",
    "    model = ARIMA(train_data, order=order)\n",
    "    model_fit = model.fit()\n",
    "    forecast = model_fit.forecast(steps=len(test_data))\n",
    "    return forecast\n",
    "\n",
    "def garch_forecast(residuals, test_length, p, q):\n",
    "    model = arch_model(residuals, vol='GARCH', p=p, q=q)\n",
    "    model_fit = model.fit(disp='off')\n",
    "    forecast = model_fit.forecast(horizon=test_length)\n",
    "    garch_forecast = np.sqrt(forecast.variance.values[-1, :])\n",
    "    return pd.Series(garch_forecast)\n",
    "\n",
    "def lstm_forecast(train_data, test_data, hidden_units, epochs):\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaled_train = scaler.fit_transform(train_data.values.reshape(-1, 1))\n",
    "\n",
    "    X_train, y_train = [], []\n",
    "    for i in range(5, len(scaled_train)):\n",
    "        X_train.append(scaled_train[i-5:i, 0])\n",
    "        y_train.append(scaled_train[i, 0])\n",
    "\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_units, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=1, verbose=0)\n",
    "\n",
    "    inputs = train_data.values[-5:].reshape(-1, 1)\n",
    "    inputs = np.append(inputs, test_data.values.reshape(-1, 1), axis=0)\n",
    "    inputs_scaled = scaler.transform(inputs)\n",
    "\n",
    "    X_test = []\n",
    "    for i in range(5, len(inputs_scaled)):\n",
    "        X_test.append(inputs_scaled[i-5:i, 0])\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "    lstm_pred = model.predict(X_test)\n",
    "    lstm_pred = scaler.inverse_transform(lstm_pred)\n",
    "    return pd.Series(lstm_pred.flatten(), index=test_data.index)"
   ],
   "id": "2916f7d40e398b6b",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def forecast_models(data, model_choice, params):\n",
    "    train_size = int(len(data) * 0.75)\n",
    "    train_data, test_data = data[:train_size], data[train_size:]\n",
    "\n",
    "    if model_choice == 'ARIMA':\n",
    "        order = params.get('arima_order', (1, 1, 1))\n",
    "        forecast = arima_forecast(train_data, test_data, order)\n",
    "    elif model_choice == 'GARCH':\n",
    "        # First, fit ARIMA to get residuals\n",
    "        arima_order = params.get('arima_order', (1, 1, 1))\n",
    "        arima_model = ARIMA(train_data, order=arima_order)\n",
    "        arima_fit = arima_model.fit()\n",
    "        residuals = arima_fit.resid\n",
    "        p = params.get('garch_p', 1)\n",
    "        q = params.get('garch_q', 1)\n",
    "        forecast = garch_forecast(residuals, len(test_data), p, q)\n",
    "    elif model_choice == 'LSTM':\n",
    "        hidden_units = params.get('hidden_units', 50)\n",
    "        epochs = params.get('epochs', 10)\n",
    "        forecast = lstm_forecast(train_data, test_data, hidden_units, epochs)\n",
    "    elif model_choice == 'Hybrid':\n",
    "        # ARIMA Forecast\n",
    "        order = params.get('arima_order', (1, 1, 1))\n",
    "        arima_pred = arima_forecast(train_data, test_data, order)\n",
    "        # GARCH Forecast on ARIMA Residuals\n",
    "        residuals = ARIMA(train_data, order=order).fit().resid\n",
    "        p = params.get('garch_p', 1)\n",
    "        q = params.get('garch_q', 1)\n",
    "        garch_pred = garch_forecast(residuals, len(test_data), p, q)\n",
    "        # LSTM Forecast on Residuals\n",
    "        residual_series = pd.Series(residuals[-len(train_data):], index=train_data.index)\n",
    "        hidden_units = params.get('hidden_units', 50)\n",
    "        epochs = params.get('epochs', 10)\n",
    "        lstm_pred = lstm_forecast(residual_series, test_data, hidden_units, epochs)\n",
    "        # Combine Forecasts\n",
    "        forecast = arima_pred + garch_pred + lstm_pred\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model choice.\")\n",
    "\n",
    "    return forecast, test_data"
   ],
   "id": "a1c4ea3314dcf265"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T21:08:51.018717Z",
     "start_time": "2024-09-11T21:08:51.013710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SCAOptimizer:\n",
    "    def __init__(self, pop_size, max_iters, dim, lb, ub):\n",
    "        self.pop_size = pop_size\n",
    "        self.max_iters = max_iters\n",
    "        self.dim = dim\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.population = np.random.uniform(lb, ub, (pop_size, dim))\n",
    "\n",
    "    def optimize(self, fitness_func):\n",
    "        best_pos = None\n",
    "        best_fit = float('inf')\n",
    "\n",
    "        for t in tqdm(range(self.max_iters), desc=\"SCA Optimizer Progress\"):\n",
    "            for i in range(self.pop_size):\n",
    "                fitness = fitness_func(self.population[i])\n",
    "                if fitness < best_fit:\n",
    "                    best_fit = fitness\n",
    "                    best_pos = self.population[i]\n",
    "\n",
    "            # SCA algorithm to update positions\n",
    "            a = 2 * (1 - t / self.max_iters)\n",
    "            for i in range(self.pop_size):\n",
    "                for j in range(self.dim):\n",
    "                    r1 = a - t * (a / self.max_iters)\n",
    "                    r2 = 2 * np.pi * np.random.rand()\n",
    "                    r3 = np.random.rand()\n",
    "                    r4 = np.random.rand()\n",
    "\n",
    "                    if r4 < 0.5:\n",
    "                        self.population[i, j] = self.population[i, j] + (r1 * np.sin(r2) * abs(r3 * best_pos[j] - self.population[i, j]))\n",
    "                    else:\n",
    "                        self.population[i, j] = self.population[i, j] + (r1 * np.cos(r2) * abs(r3 * best_pos[j] - self.population[i, j]))\n",
    "\n",
    "            # Make sure values stay within bounds\n",
    "            self.population = np.clip(self.population, self.lb, self.ub)\n",
    "\n",
    "        return best_pos, best_fit\n",
    "\n",
    "def calculate_fitness(predictions, actual):\n",
    "    return np.sqrt(np.mean((predictions - actual) ** 2))\n"
   ],
   "id": "c46ff39aee246d79",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 97,
   "source": [
    "\"\"\"\n",
    "def forecast_arima_garch_lstm(data, best_params):\n",
    "    long_term, seasonal, residual = DataPreprocessing(data).decompose_data()\n",
    "\n",
    "    # Split long-term and residual data for train/test\n",
    "    train_len = int(0.75 * len(long_term))\n",
    "    test_len = len(long_term) - train_len\n",
    "\n",
    "    # ARIMA-GARCH Forecast\n",
    "    arima_garch_predictions = arima_forecast(long_term[:train_len],\n",
    "                                             long_term[train_len:],\n",
    "                                             order=(int(best_params[0]), 1, int(best_params[1])))\n",
    "\n",
    "    # LSTM Forecast\n",
    "    lstm_predictions = lstm_forecast(residual[:train_len],\n",
    "                                     residual[train_len:],\n",
    "                                     hidden_units=int(best_params[2]),\n",
    "                                     epochs=int(best_params[3]))\n",
    "\n",
    "    # Combine forecasts (adjusting lengths)\n",
    "    min_len = min(len(arima_garch_predictions), len(lstm_predictions))\n",
    "    arima_garch_predictions = arima_garch_predictions[-min_len:]\n",
    "    lstm_predictions = lstm_predictions[-min_len:]\n",
    "\n",
    "    combined_forecast = arima_garch_predictions + lstm_predictions\n",
    "\n",
    "    return combined_forecast\n",
    "\"\"\""
   ],
   "id": "56810348786f053"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 85,
   "source": [
    "\"\"\"# ARIMA-GARCH Forecasting\n",
    "def arima_garch_forecast(train_data, test_data, p, q):\n",
    "    \n",
    "    Forecast using ARIMA-GARCH model.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_data (pd.Series): Training data for the ARIMA-GARCH model.\n",
    "    - test_data (pd.Series): Testing data for forecasting.\n",
    "    - p (int): ARIMA p parameter (autoregressive term).\n",
    "    - q (int): GARCH q parameter (lagged residual error term).\n",
    "    \n",
    "    Returns:\n",
    "    - forecast (pd.Series): Combined forecast of ARIMA and GARCH models.\n",
    "    \n",
    "    # Fit ARIMA model\n",
    "    arima_model = ARIMA(train_data, order=(p, 1, q))\n",
    "    arima_fitted = arima_model.fit()\n",
    "\n",
    "    # Fit GARCH model on ARIMA residuals\n",
    "    residuals = arima_fitted.resid\n",
    "    garch_model = arch_model(residuals, vol=\"GARCH\", p=p, q=q)\n",
    "    garch_fitted = garch_model.fit(disp=\"off\")\n",
    "\n",
    "    # Forecast for ARIMA and GARCH\n",
    "    arima_forecast = arima_fitted.forecast(steps=len(test_data))\n",
    "\n",
    "    # Forecast GARCH and get the mean forecast for the future time steps\n",
    "    garch_forecast_result = garch_fitted.forecast(horizon=len(test_data), start=len(residuals)-1)\n",
    "\n",
    "    # Extract GARCH forecast and ensure it's for multiple steps\n",
    "    garch_forecast = garch_forecast_result.variance[-len(test_data):].values.flatten()\n",
    "\n",
    "    print(\"ARIMA forecast length:\", len(arima_forecast))\n",
    "    print(\"GARCH forecast length:\", len(garch_forecast))\n",
    "\n",
    "    # Combine the ARIMA and GARCH forecasts\n",
    "    forecast = arima_forecast + garch_forecast\n",
    "\n",
    "    return forecast\n",
    "\"\"\"\n"
   ],
   "id": "2ecd8ad5ad3c1360"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 86,
   "source": [
    "\"\"\"\n",
    "def lstm_forecast(train_data, test_data, hidden_units, max_epochs):\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    train_scaled = scaler.fit_transform(train_data.values.reshape(-1, 1))\n",
    "\n",
    "    X_train, y_train = [], []\n",
    "    for i in range(5, len(train_scaled)):\n",
    "        X_train.append(train_scaled[i-5:i, 0])\n",
    "        y_train.append(train_scaled[i, 0])\n",
    "\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.LSTM(units=hidden_units, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=max_epochs, batch_size=1, verbose=2)\n",
    "\n",
    "    total_data = pd.concat((train_data, test_data), axis=0)\n",
    "    inputs = total_data[len(total_data) - len(test_data) - 5:].values.reshape(-1, 1)\n",
    "    inputs_scaled = scaler.transform(inputs)\n",
    "\n",
    "    X_test = []\n",
    "    for i in range(5, len(inputs_scaled)):\n",
    "        X_test.append(inputs_scaled[i-5:i, 0])\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    lstm_predictions = model.predict(X_test)\n",
    "    lstm_predictions = scaler.inverse_transform(lstm_predictions)\n",
    "\n",
    "    return lstm_predictions.flatten()\n",
    "\"\"\""
   ],
   "id": "b873d0692847bda7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T21:08:52.331004Z",
     "start_time": "2024-09-11T21:08:52.327063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forecast_arima_garch_lstm(data, best_params):\n",
    "    long_term, seasonal, residual = DataPreprocessing(data).decompose_data()\n",
    "\n",
    "    # Split long-term and residual data for train/test\n",
    "    train_len = int(0.75 * len(long_term))\n",
    "    test_len = len(long_term) - train_len\n",
    "\n",
    "    # ARIMA-GARCH Forecast\n",
    "    arima_garch_predictions = arima_garch_forecast(long_term[:train_len],\n",
    "                                                   long_term[train_len:],\n",
    "                                                   p=int(best_params[0]), q=int(best_params[1]))\n",
    "\n",
    "    # LSTM Forecast\n",
    "    lstm_predictions = lstm_forecast(residual[:train_len],\n",
    "                                     residual[train_len:],\n",
    "                                     hidden_units=int(best_params[2]), max_epochs=int(best_params[3]))\n",
    "\n",
    "    # Align ARIMA-GARCH and LSTM lengths if different\n",
    "    min_len = min(len(arima_garch_predictions), len(lstm_predictions))\n",
    "    arima_garch_predictions = arima_garch_predictions[-min_len:]\n",
    "    lstm_predictions = lstm_predictions[-min_len:]\n",
    "\n",
    "    # Combine predictions\n",
    "    combined_forecast = arima_garch_predictions + lstm_predictions\n",
    "\n",
    "    return combined_forecast"
   ],
   "id": "25d280d2ebbd9326",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T21:08:53.007494Z",
     "start_time": "2024-09-11T21:08:53.004303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert differenced values back to stock prices\n",
    "def reverse_differencing(actual_data, predicted_diff):\n",
    "    \"\"\"\n",
    "    Reverse the differencing to convert predicted differences back to stock prices.\n",
    "    \n",
    "    Parameters:\n",
    "    - actual_data (pd.Series): The actual stock price series (used to get the last known price).\n",
    "    - predicted_diff (pd.Series or np.array): The predicted differenced values.\n",
    "    \n",
    "    Returns:\n",
    "    - predicted_stock_prices (pd.Series): The predicted stock prices.\n",
    "    \"\"\"\n",
    "    last_actual_price = actual_data.iloc[-1]  # Get the last actual stock price\n",
    "    predicted_stock_prices = np.r_[last_actual_price, predicted_diff].cumsum()  # Reverse the differencing\n",
    "    return predicted_stock_prices[1:]  # Return all except the first element which is just the last actual price\n"
   ],
   "id": "9181b1b1ab05078d",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T21:08:53.904934Z",
     "start_time": "2024-09-11T21:08:53.901044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Update the save_results_to_csv method to include both differenced and actual prices\n",
    "def save_results_to_csv(original_data, actual_data, forecast_diff, filename='../data/processed/^SPX_Predicted.csv'):\n",
    "    \"\"\"\n",
    "    Save the actual, predicted differenced values, and predicted stock prices to a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    - actual_data (pd.Series): Actual stock prices.\n",
    "    - forecast_diff (pd.Series): Forecasted differenced values.\n",
    "    - filename (str): Output filename for the CSV.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    predicted_stock_prices = reverse_differencing(actual_data, forecast_diff)\n",
    "\n",
    "    results_df = original_data.copy()\n",
    "    results_df['Predicted_Difference_Adj_Close'] = np.nan\n",
    "    results_df['Predicted_Adj_Close'] = np.nan\n",
    "\n",
    "    # Fill the predictions only for the forecasted period\n",
    "    results_df.iloc[-len(predicted_stock_prices):, results_df.columns.get_loc('Predicted_Difference_Adj_Close')] = forecast_diff\n",
    "    results_df.iloc[-len(predicted_stock_prices):, results_df.columns.get_loc('Predicted_Adj_Close')] = predicted_stock_prices\n",
    "\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    print(f\"Results saved to {filename}\")"
   ],
   "id": "d223ccf4eb159195",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T21:08:54.622948Z",
     "start_time": "2024-09-11T21:08:54.619555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Updating plot_results to show both predicted differenced values and stock prices\n",
    "def plot_results(actual, forecast_diff):\n",
    "    \"\"\"\n",
    "    Plot the actual and forecasted values (for differenced and stock prices).\n",
    "    \n",
    "    Parameters:\n",
    "    - actual (pd.Series): Actual stock prices.\n",
    "    - forecast_diff (pd.Series): Forecasted differenced values from the model.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    predicted_stock_prices = reverse_differencing(actual, forecast_diff)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(actual.index, actual, label=\"Actual Data\", color='steelblue', linewidth=2)\n",
    "    plt.plot(actual.index[-len(predicted_stock_prices):], predicted_stock_prices, label=\"Predicted Stock Price\", linestyle=\"--\", color='orange', linewidth=2)\n",
    "    plt.title(\"ARIMA-GARCH-LSTM Predictions (Stock Prices)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "67121fdfa031744e",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T21:08:55.322858Z",
     "start_time": "2024-09-11T21:08:55.318477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_full_workflow(data,original_data, best_params=None, best_fitness=None):\n",
    "    \"\"\"\n",
    "    Run the full ARIMA-GARCH-LSTM workflow. Optionally, provide best parameters and fitness.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input stock price data.\n",
    "    - best_params (list): Predefined best parameters for the model (optional).\n",
    "    - best_fitness (float): Predefined best fitness value (optional).\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Decompose the data\n",
    "    preprocessing = DataPreprocessing(data)\n",
    "    long_term, seasonal, residual = preprocessing.decompose_data()\n",
    "\n",
    "    # Define bounds for SCA optimization\n",
    "    lb = [1, 1, 10, 10]  # p, q, hidden_units, max_epochs\n",
    "    ub = [5, 5, 100, 100]\n",
    "\n",
    "    # Check if best_params and best_fitness are provided\n",
    "    if best_params is None or best_fitness is None:\n",
    "        # If not provided, run SCA optimizer\n",
    "        print(\"No predefined parameters provided. Running SCA optimization...\")\n",
    "        sca_optimizer = SCAOptimizer(pop_size=1, max_iters=1, dim=4, lb=lb, ub=ub)\n",
    "\n",
    "        # Run SCA optimization\n",
    "        best_params, best_fitness = sca_optimizer.optimize(lambda params: calculate_fitness(forecast_arima_garch_lstm(data, params), data))\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}, Best Fitness: {best_fitness}\")\n",
    "\n",
    "    forecast_diff = forecast_arima_garch_lstm(data, best_params)\n",
    "\n",
    "    save_results_to_csv(original_data, data, forecast_diff)\n",
    "    plot_results(data, forecast_diff)\n",
    "\n",
    "\n"
   ],
   "id": "668e71281b98b840",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "data = pd.read_csv('../data/processed/^SPX.csv')\n",
    "\n",
    "best_params = [2.83233556, 2.81456431, 119.79685995, -15.86869918]\n",
    "best_fitness = 3.543810119195985\n",
    "run_full_workflow(data['Differenced_Adj_Close'], data)"
   ],
   "id": "14fc496735c4a447"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T01:02:24.559865Z",
     "start_time": "2024-09-11T01:02:24.555470Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "42b029b6567cc34a",
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T01:02:24.564249Z",
     "start_time": "2024-09-11T01:02:24.560874Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2b8083c24710e850",
   "outputs": [],
   "execution_count": 142
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
