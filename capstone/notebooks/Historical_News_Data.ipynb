{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Historical News Data Collection and Processing\n",
    "\n",
    "## Overview:\n",
    "This notebook is designed to fetch and store historical news data related to stock tickers using the EODHD API. The news data can then be used for further analysis, such as sentiment analysis or correlation with stock price movements.\n",
    "\n",
    "## Purpose:\n",
    "The primary goal of this notebook is to automate the process of retrieving and storing news articles for specified stock tickers over a given date range. The notebook processes the news data and exports it to CSV format for ease of analysis.\n",
    "\n",
    "## Steps:\n",
    "1. **Setup and Imports**: The notebook starts by importing the required libraries, such as `pandas` for data manipulation and `requests` for making API calls.\n",
    "2. **API Configuration**: We define the API key and base URL for fetching news data from the EODHD API. The user specifies parameters like the ticker symbol, date range, and maximum number of articles to fetch.\n",
    "3. **Data Fetching**: The `fetch_news_data` function is responsible for making API requests and retrieving news data for the specified stock ticker. It handles pagination to retrieve large datasets and checks for errors in the API response.\n",
    "4. **Data Saving**: The `save_to_csv` function exports the news data into a CSV file format, with the file name based on the ticker symbol and stored in a specified folder.\n",
    "5. **Workflow Execution**: The `run_workflow` function ties everything together, fetching the data and saving it to CSV. It is designed to be easy to run for multiple tickers and date ranges.\n",
    "6. **Execution Example**: The final step in the notebook demonstrates how to define a stock ticker and date range, and execute the workflow to fetch the news data for that ticker.\n",
    "\n",
    "## Output:\n",
    "- CSV files containing the fetched news data are saved in a specified folder. The file names are formatted as `<ticker>_news.csv` (e.g., `SPY.US_news.csv` for S&P 500 data).\n",
    "\n",
    "## Use Cases:\n",
    "- **Historical Sentiment Analysis**: Use the historical news data for performing sentiment analysis to understand market sentiment around a specific stock or index.\n",
    "- **Correlation Studies**: Analyze the correlation between stock price movements and specific news events over time.\n",
    "- **Backtesting**: Incorporate the news data into backtesting frameworks for trading strategies that rely on news sentiment or historical events.\n",
    "\n",
    "## Customization:\n",
    "The user can modify the following:\n",
    "- **API Key**: Replace the placeholder API key with a valid key.\n",
    "- **Ticker and Date Range**: Update the ticker symbol and date range to fetch news data for different stocks or time periods.\n",
    "- **Maximum Articles**: Adjust the `max_articles` parameter to control how much data to fetch per ticker.\n",
    "\n",
    "## Requirements:\n",
    "- **EODHD API Key**: A valid API key for the EODHD service is required to fetch news data.\n",
    "- **Libraries**: Ensure that `pandas` and `requests` are installed in the environment to handle data manipulation and API requests.\n",
    "\n",
    "## Conclusion:\n",
    "This notebook provides an efficient and scalable way to fetch historical news data for multiple stock tickers over extended time periods. It can be easily integrated into larger workflows for financial analysis, trading strategies, or research projects.\n"
   ],
   "id": "9e5f55c549d827f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Importing libraries\n",
    "This cell imports the necessary libraries for fetching news data and saving it as a CSV file.\n",
    "- `pandas`: Used for handling data and saving it to a CSV file.\n",
    "- `requests`: Used for making HTTP requests to fetch data from the EODHD API."
   ],
   "id": "6e2381a5a65f3916"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-13T16:28:10.906304Z",
     "start_time": "2024-09-13T16:28:10.903055Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import requests"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Setup API key and basic configuration\n",
    "This cell sets up the API key and other parameters needed for fetching news data from the EODHD API. It defines:\n",
    "- `api_key`: The API key for accessing the EODHD API (replace with your own).\n",
    "- `base_url`: The base URL for fetching news data.\n",
    "- `limit`: Maximum number of articles per request (100 by default).\n",
    "- `max_articles`: The maximum number of articles to fetch for each ticker (500 in this case).\n"
   ],
   "id": "104e914929e7f978"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:28:12.025804Z",
     "start_time": "2024-09-13T16:28:12.022089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup and Imports\n",
    "api_key = \" 66848eff49cbd1.37105331\"  # Replace with your EODHD API key\n",
    "base_url = \"https://eodhd.com/api/news\"\n",
    "limit = 100  # The number of articles per request (max 1000, default 50)\n",
    "max_articles = 500  # Define the maximum number of articles to fetch\n"
   ],
   "id": "b3b2436f03967226",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Function to fetch news data from EODHD API\n",
    "This function fetches historical news articles for a given stock ticker and date range. It makes multiple requests if necessary to get all the data up to `max_articles`.\n",
    "\n",
    "**Parameters:**\n",
    "- `ticker`: The stock ticker symbol.\n",
    "- `start_date`: Start date for fetching news (format: 'YYYY-MM-DD').\n",
    "- `end_date`: End date for fetching news (format: 'YYYY-MM-DD').\n",
    "- `limit`: The number of articles per request.\n",
    "- `api_key`: The API key for authentication.\n",
    "- `max_articles`: Maximum number of articles to fetch.\n",
    "\n",
    "**Returns:**\n",
    "- A list of all news articles fetched from the API."
   ],
   "id": "18c46802bf56004d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:28:12.891291Z",
     "start_time": "2024-09-13T16:28:12.886440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_news_data(ticker, start_date, end_date, limit, api_key, max_articles=500):\n",
    "    offset = 0\n",
    "    all_news_data = []\n",
    "\n",
    "    while True:\n",
    "        url = f\"{base_url}?s={ticker}&from={start_date}&to={end_date}&limit={limit}&offset={offset}&api_token={api_key}&fmt=json\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            news_data = response.json()\n",
    "            if not news_data:\n",
    "                break  # Break the loop if no more data is returned\n",
    "\n",
    "            all_news_data.extend(news_data)\n",
    "\n",
    "            # Increment the offset for the next batch of data\n",
    "            offset += limit\n",
    "\n",
    "            # Check if we've reached the max number of articles to fetch\n",
    "            if len(all_news_data) >= max_articles:\n",
    "                break  # Stop fetching more if we reach the maximum limit\n",
    "        else:\n",
    "            print(f\"Failed to fetch data: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "    return all_news_data"
   ],
   "id": "dcc322b30559e2f3",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Function to save news data to a CSV file\n",
    "This function saves the fetched news data into a CSV file for further analysis.\n",
    "\n",
    "**Parameters:**\n",
    "- `data`: The DataFrame containing the fetched news data.\n",
    "- `ticker`: The stock ticker symbol.\n",
    "- `folder`: The folder path where the file will be saved (default: 'data').\n",
    "\n",
    "**Returns:**\n",
    "- None: The file is saved in the specified folder."
   ],
   "id": "600876a9e7fbfb9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:28:13.855597Z",
     "start_time": "2024-09-13T16:28:13.851547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_to_csv(data, ticker, folder='data'):\n",
    "    \"\"\"\n",
    "    Save the news data to a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    data (pd.DataFrame): News Data\n",
    "    ticker (str): Stock ticker symbol.\n",
    "    folder (str): Folder path to save the CSV.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    filename = f\"../{folder}/processed/{ticker}_news.csv\"\n",
    "    data.to_csv(filename)\n",
    "    print(f\"Data saved to {filename}\")"
   ],
   "id": "c04f8d6606ecb8cc",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Main workflow function\n",
    "This function orchestrates the entire process of fetching the news data, saving it to a CSV file, and handling any necessary logic.\n",
    "\n",
    "**Parameters:**\n",
    "- `ticker`: The stock ticker symbol.\n",
    "- `start_date`: The start date for the data collection.\n",
    "- `end_date`: The end date for the data collection.\n",
    "\n",
    "**Returns:**\n",
    "- None: Saves the news data to a CSV file if data is fetched successfully."
   ],
   "id": "4bf16a4f312bdb17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:28:17.230168Z",
     "start_time": "2024-09-13T16:28:17.226305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_workflow(ticker, start_date, end_date):\n",
    "    \n",
    "    news_data = fetch_news_data(ticker, start_date, end_date, limit=500, api_key=api_key, max_articles=500)\n",
    "    \n",
    "    if news_data:\n",
    "        save_to_csv(pd.DataFrame(news_data), ticker, folder='data')\n",
    "    \n",
    "    "
   ],
   "id": "5aa339293785f310",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Define ticker and date range, then run the workflow\n",
    "This cell defines the stock ticker symbol (e.g., `SPY.US` for S&P 500) and the date range for fetching news data. It then calls the `run_workflow` function to fetch, process, and save the news data.\n",
    "\n",
    "**Parameters defined:**\n",
    "- `ticker`: The stock ticker symbol (e.g., 'SPY.US').\n",
    "- `start_date`: The start date of the news data ('2010-01-01').\n",
    "- `end_date`: The end date of the news data ('2024-09-10')."
   ],
   "id": "597318cc0b97f5ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T16:28:29.135682Z",
     "start_time": "2024-09-13T16:28:20.240482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define tickers (example for S&P 500 or other stocks)\n",
    "ticker = 'SPY.US'  # Use the normalized ticker for S&P 500 (example: SPX for S&P 500)\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2024-09-10'\n",
    "\n",
    "run_workflow(ticker, start_date, end_date)"
   ],
   "id": "310d19aab90b16a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../data/processed/SPY.US_news.csv\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5e4c9b0522ac23c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
